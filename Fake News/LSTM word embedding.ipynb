{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e815d059",
   "metadata": {},
   "source": [
    "# Fake News Classifier : Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba12c80",
   "metadata": {},
   "source": [
    "Libraries: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abf7738",
   "metadata": {},
   "source": [
    "    Link: https://www.kaggle.com/c/fake-news/data\n",
    "    Dataset: \n",
    "        id: unique id for a news article\n",
    "        title: the title of a news article\n",
    "        author: author of the news article\n",
    "        text: the text of the article; could be incomplete\n",
    "        label: a label that marks the article as potentially unreliable\n",
    "            1: unreliable\n",
    "            0: reliable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca6cb177",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b739b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('fake-news/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b61556e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title              author  \\\n",
       "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
       "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
       "2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n",
       "3   3  15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n",
       "4   4  Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n",
       "\n",
       "                                                text  label  \n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
       "1  Ever get the feeling your life circles the rou...      0  \n",
       "2  Why the Truth Might Get You Fired October 29, ...      1  \n",
       "3  Videos 15 Civilians Killed In Single US Airstr...      1  \n",
       "4  Print \\nAn Iranian woman has been sentenced to...      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffff3125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20800, 5)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d15f986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id           0\n",
       "title      558\n",
       "author    1957\n",
       "text        39\n",
       "label        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "147de641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Nan Values\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0239891c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('label',axis=1)\n",
    "Y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10b63d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18285, 4) (18285,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5451756b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63132b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16d661a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e42c58ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary Size\n",
    "voc_size = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac76d0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9d6acd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    FLYNN: Hillary Clinton, Big Woman on Campus - ...\n",
       "2                    Why the Truth Might Get You Fired\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages['title'][1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0647454b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have Dropped Nan values before so, reset_index() method sets a list of \n",
    "# integer ranging from 0 to length of data as index\n",
    "messages.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0077bf13",
   "metadata": {},
   "source": [
    "### Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8fe7a900",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "import re\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e9a9e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\aakriti\n",
      "[nltk_data]     aggarwal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea5a0274",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "corpus = []\n",
    "for i in range(0,len(messages)):\n",
    "    # print(i)\n",
    "    review = re.sub('[^a-zA-z]',' ', messages['title'][i])\n",
    "    # substituting everything with blank except alphabets\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)\n",
    "# First for each index sentence, except all the alphabets all the words will be subsituted to ' '\n",
    "# then conver each word into lowercase and split each word separately in the sentence.\n",
    "# for each word not present in stopwords then only that word is stored in review\n",
    "# again join the words that were splitted for forming a sentence and append together each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41ea84fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hous dem aid even see comey letter jason chaffetz tweet',\n",
       " 'flynn hillari clinton big woman campu breitbart',\n",
       " 'truth might get fire',\n",
       " 'civilian kill singl us airstrik identifi',\n",
       " 'iranian woman jail fiction unpublish stori woman stone death adulteri']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:5]\n",
    "# all the non necessary word is removed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63094aa4",
   "metadata": {},
   "source": [
    "### One Hot Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c15b06ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2177, 1069, 2453, 420, 2446, 3839, 2411, 2959, 4623, 2965], [3346, 2427, 2126, 353, 1265, 2904, 2693], [2446, 19, 711, 3808], [4559, 3158, 4612, 967, 4600, 1215], [37, 1265, 4246, 180, 4514, 4549, 1265, 741, 4745, 4459]]\n"
     ]
    }
   ],
   "source": [
    "onehotRep = [one_hot(words, voc_size) for words in corpus]\n",
    "print(onehotRep[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a2958a",
   "metadata": {},
   "source": [
    "### Embedding Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c975caa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0    0    0    0    0    0    0 2177 1069 2453  420\n",
      "  2446 3839 2411 2959 4623 2965]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0 3346\n",
      "  2427 2126  353 1265 2904 2693]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0 2446   19  711 3808]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "  4559 3158 4612  967 4600 1215]\n",
      " [   0    0    0    0    0    0    0    0    0    0   37 1265 4246  180\n",
      "  4514 4549 1265  741 4745 4459]]\n"
     ]
    }
   ],
   "source": [
    "# All the sent have variable len; using pad_sequence fix the len\n",
    "sent_len = 20\n",
    "embedded_docs = pad_sequences(onehotRep, padding = 'pre', maxlen = sent_len)\n",
    "print(embedded_docs[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01483bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18285"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedded_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eebbe5b",
   "metadata": {},
   "source": [
    "## Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fb273096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 20, 40)            200000    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 100)               56400     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 256,501\n",
      "Trainable params: 256,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embedding_vector_features = 40\n",
    "model = Sequential()\n",
    "model.add(Embedding(voc_size, embedding_vector_features, input_length=sent_len))\n",
    "model.add(LSTM(100)) # 1 LSTM layer having 100 neurons\n",
    "model.add(Dense(1,activation='sigmoid')) # coz of classification prob\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd486054",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_final = np.array(embedded_docs)\n",
    "Y_final = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c807f886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18285, 20) (18285,)\n"
     ]
    }
   ],
   "source": [
    "print(X_final.shape, Y_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2b71f6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X_final, Y_final, \n",
    "                                                test_size = 0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa540b04",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d95fe190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.3324 - accuracy: 0.8441 - val_loss: 0.1918 - val_accuracy: 0.9182\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 8s 42ms/step - loss: 0.1328 - accuracy: 0.9501 - val_loss: 0.1971 - val_accuracy: 0.9192\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 8s 42ms/step - loss: 0.0994 - accuracy: 0.9631 - val_loss: 0.2122 - val_accuracy: 0.9167\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 8s 42ms/step - loss: 0.0724 - accuracy: 0.9746 - val_loss: 0.2354 - val_accuracy: 0.9110\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 8s 42ms/step - loss: 0.0525 - accuracy: 0.9824 - val_loss: 0.3155 - val_accuracy: 0.9154\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 8s 41ms/step - loss: 0.0369 - accuracy: 0.9881 - val_loss: 0.3641 - val_accuracy: 0.9131\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 8s 41ms/step - loss: 0.0274 - accuracy: 0.9915 - val_loss: 0.3632 - val_accuracy: 0.9141\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 8s 42ms/step - loss: 0.0172 - accuracy: 0.9944 - val_loss: 0.4397 - val_accuracy: 0.9063\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 8s 41ms/step - loss: 0.0129 - accuracy: 0.9966 - val_loss: 0.5443 - val_accuracy: 0.9112\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 8s 42ms/step - loss: 0.0064 - accuracy: 0.9985 - val_loss: 0.5950 - val_accuracy: 0.9059\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e5e8144760>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xtrain,Ytrain,validation_data = (Xtest,Ytest), epochs=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "357a6b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the accuracy is 0.9996 almost 1.0 it may lead to overfitting prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bd2e2a",
   "metadata": {},
   "source": [
    "## Performance Metrics and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d3b080f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-29-e0468a8fd79a>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0ba6900e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2884,  223],\n",
       "       [ 293, 2086]], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(Ytest,y_pred)\n",
    "# False + and False - are very less compare to True + and True -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "193570c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9059423988333941"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Ytest,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5118d6e",
   "metadata": {},
   "source": [
    "## Adding Dropout (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "36a99e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 20, 40)            200000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 150)               114600    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 151       \n",
      "=================================================================\n",
      "Total params: 314,751\n",
      "Trainable params: 314,751\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "## creating Model\n",
    "embedding_vector_features = 40\n",
    "model = Sequential()\n",
    "model.add(Embedding(voc_size, embedding_vector_features, input_length=sent_len))\n",
    "model.add(LSTM(150)) # 1 LSTM layer having 100 neurons\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(1,activation='sigmoid')) # coz of classification prob\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f6e788b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 0.3300 - accuracy: 0.8458 - val_loss: 0.1988 - val_accuracy: 0.9158\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 10s 51ms/step - loss: 0.1414 - accuracy: 0.9491 - val_loss: 0.2015 - val_accuracy: 0.9178\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 10s 52ms/step - loss: 0.0973 - accuracy: 0.9644 - val_loss: 0.2148 - val_accuracy: 0.9174\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 10s 51ms/step - loss: 0.0767 - accuracy: 0.9733 - val_loss: 0.2526 - val_accuracy: 0.9147\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 10s 52ms/step - loss: 0.0505 - accuracy: 0.9830 - val_loss: 0.2844 - val_accuracy: 0.9118\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 10s 52ms/step - loss: 0.0349 - accuracy: 0.9891 - val_loss: 0.3924 - val_accuracy: 0.9043\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 11s 53ms/step - loss: 0.0262 - accuracy: 0.9922 - val_loss: 0.4232 - val_accuracy: 0.9096\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 11s 53ms/step - loss: 0.0154 - accuracy: 0.9958 - val_loss: 0.4891 - val_accuracy: 0.9063\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 10s 52ms/step - loss: 0.0142 - accuracy: 0.9961 - val_loss: 0.5458 - val_accuracy: 0.9125\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 11s 53ms/step - loss: 0.0068 - accuracy: 0.9980 - val_loss: 0.4885 - val_accuracy: 0.9107\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e5f3f0bca0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xtrain,Ytrain,validation_data = (Xtest,Ytest), epochs=10, batch_size=64)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
